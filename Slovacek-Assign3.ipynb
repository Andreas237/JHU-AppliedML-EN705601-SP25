{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff456234-feec-4311-baaa-224629c93f4b",
   "metadata": {},
   "source": [
    "# Overview\n",
    "From the Kaggle web site (https://www.kaggle.com/datasets) download the Suicide Rates Overview 1985 to 2016 dataset. This dataset has 12 features and 27820 data points. In this assignment we would like to develop a machine learned model to predict, given some feature vectors, if the outcome would be suicide or not, as a binary dependent variable. The binary categories could be {\"low suicide rate\", \"high suicide rate\"}. (Note that a different approach could seek to generate a numerical value by solving a regression problem.)\n",
    "\n",
    "\n",
    "A machine learning solution would require us to pre-process the dataset and prepare/design our experimentation.\n",
    "\n",
    "\n",
    "Load the dataset in your model development framework (Jupyter notebook) and examine the features. Note that the Kaggle website also has histograms that you can inspect. However, you might want to look at the data grouped by some other features. For example, what does the 'number of suicides / 100k' histogram look like from country to country?\n",
    "\n",
    "\n",
    "To answer the following questions, you have to think thoroughly, and possibly attempt some pilot experiments. There is no one right or wrong answer to some questions below, but you will always need to work from the data to build a convincing argument for your audience."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27347717-2e58-4db1-ad9c-5ae5925105ee",
   "metadata": {},
   "source": [
    "### 1. [10 pts] Due to the severity of this real-world crisis, what information would be the most important to \"machine learn\"? Can it be learned? (Note that this is asking you to define the big-picture question that we want to answer from this dataset. This is not asking you to conjecture which feature is going to turn out being important."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1bff51-9537-404b-a611-7ef27ed5dba3",
   "metadata": {},
   "source": [
    "#### 1. Answer\n",
    "\n",
    "In my opinion the most important thing to determine with the dataset is what causes suicides.  It seems a problem people struggle to understand, therefore teaching a machine to understand it wouldn't be possible.  Maybe we could teach a machine to observe for causes of suicide.  I think a machine can be taught to observe for causes of suicide, and how likely they are to occur in a population or an individual.  It seems unlikely that we will be able to do that with this dataset.  The data has too few features-- `year` and `generation` are tightly correlated, as are `year` and `country-year`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a828cad-7e4b-4073-92f0-b85456a81b92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#rows=27820 #columns=12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>suicides_no</th>\n",
       "      <th>population</th>\n",
       "      <th>suicides/100k pop</th>\n",
       "      <th>country-year</th>\n",
       "      <th>HDI for year</th>\n",
       "      <th>gdp_for_year ($)</th>\n",
       "      <th>gdp_per_capita ($)</th>\n",
       "      <th>generation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1987</td>\n",
       "      <td>male</td>\n",
       "      <td>15-24 years</td>\n",
       "      <td>21</td>\n",
       "      <td>312900</td>\n",
       "      <td>6.71</td>\n",
       "      <td>Albania1987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2156624900</td>\n",
       "      <td>796</td>\n",
       "      <td>Generation X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1987</td>\n",
       "      <td>male</td>\n",
       "      <td>35-54 years</td>\n",
       "      <td>16</td>\n",
       "      <td>308000</td>\n",
       "      <td>5.19</td>\n",
       "      <td>Albania1987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2156624900</td>\n",
       "      <td>796</td>\n",
       "      <td>Silent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1987</td>\n",
       "      <td>female</td>\n",
       "      <td>15-24 years</td>\n",
       "      <td>14</td>\n",
       "      <td>289700</td>\n",
       "      <td>4.83</td>\n",
       "      <td>Albania1987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2156624900</td>\n",
       "      <td>796</td>\n",
       "      <td>Generation X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1987</td>\n",
       "      <td>male</td>\n",
       "      <td>75+ years</td>\n",
       "      <td>1</td>\n",
       "      <td>21800</td>\n",
       "      <td>4.59</td>\n",
       "      <td>Albania1987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2156624900</td>\n",
       "      <td>796</td>\n",
       "      <td>G.I. Generation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1987</td>\n",
       "      <td>male</td>\n",
       "      <td>25-34 years</td>\n",
       "      <td>9</td>\n",
       "      <td>274300</td>\n",
       "      <td>3.28</td>\n",
       "      <td>Albania1987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2156624900</td>\n",
       "      <td>796</td>\n",
       "      <td>Boomers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country  year     sex          age  suicides_no  population  \\\n",
       "0  Albania  1987    male  15-24 years           21      312900   \n",
       "1  Albania  1987    male  35-54 years           16      308000   \n",
       "2  Albania  1987  female  15-24 years           14      289700   \n",
       "3  Albania  1987    male    75+ years            1       21800   \n",
       "4  Albania  1987    male  25-34 years            9      274300   \n",
       "\n",
       "   suicides/100k pop country-year  HDI for year   gdp_for_year ($)   \\\n",
       "0               6.71  Albania1987           NaN          2156624900   \n",
       "1               5.19  Albania1987           NaN          2156624900   \n",
       "2               4.83  Albania1987           NaN          2156624900   \n",
       "3               4.59  Albania1987           NaN          2156624900   \n",
       "4               3.28  Albania1987           NaN          2156624900   \n",
       "\n",
       "   gdp_per_capita ($)       generation  \n",
       "0                 796     Generation X  \n",
       "1                 796           Silent  \n",
       "2                 796     Generation X  \n",
       "3                 796  G.I. Generation  \n",
       "4                 796          Boomers  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 1. Experiments\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.dpi\"] = 72\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Visualizations\n",
    "import seaborn as sns; sns.set(style=\"ticks\", color_codes=True)\n",
    "\n",
    "# Locate and load the data file\n",
    "df = pd.read_csv('./datasets/master.csv', thousands=',')\n",
    "\n",
    "# Sanity\n",
    "print(f'#rows={len(df)} #columns={len(df.columns)}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d275dcc1-6f43-4ca1-895d-a38736eba543",
   "metadata": {},
   "source": [
    "### 2. [10 pts] Explain in detail how one should set up the problem. Would it be a regression or a classification problem? Is any unsupervised approach, to look for patterns, worthwhile?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0b4d97-e0c6-4d7a-be09-da17ee4360ab",
   "metadata": {},
   "source": [
    "#### 2. Answer\n",
    "Starting with the last question, \"is any unsupervised approach worthwhile,\" considering this dataset no.  The dataset has labeled features.  It might be useful do a comparison of omitting labels and testing whether an unsupervised approach finds possible relations.\n",
    "\n",
    "To address the larger question-- we could use a Decision Tree, or by extension a random forest, but this is a regression problem since we want to determine where on a numeric scale the rate of suicides per 100,000 persons will trend.  To setup the problem we will need to normalize the numeric features `HDI for year`, `gdp_for_year($)`, `gdp_per_capita ($)`, `population`, `suicides_no`, `year` (we could have standardized them too); map the ordinal features `age` and `generation`; and encode the nominal features `country` and `sex`.  \n",
    "\n",
    "We will drop the feature `country-year` since it is captured in the dataset.  We could have chosen to drop `country` and `year` however I like that year is numeric.  Additionally, I will train two version of the model, one including `suicides_no` and `population` and one without.  These two features in combination have a correlation coefficient of 1 with the target.  That doesn't answer the question _I_ am curious about, which is about what in a population makes them susceptible to suicide."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540f517f-d25b-40bb-86b9-c87eeb3f03ef",
   "metadata": {},
   "source": [
    "### 3. [20 pts] What should be the dependent variable?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f16329-165f-45bb-bac2-ec630adfdfcf",
   "metadata": {},
   "source": [
    "#### 3. Answer\n",
    "According to the dataset page on Kaggle, the dataset intends to collate information on \"suicide rates by cohort.\"  This means the `suicides/100k pop` is the target, which makes sense.  We will explore it in the next question, but that may mean we can remove `suicides_no` or `population` features for training deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e3b8e6-cc9a-484f-84f8-faed73f85dbe",
   "metadata": {},
   "source": [
    "\n",
    "### 4. [20 pts] Find some strong correlations between the independent variables and the dependent variable you decided and use them to rank the independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6222166b-00b4-41ff-92b6-472b83bf3ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country                object\n",
      "year                    int64\n",
      "sex                    object\n",
      "age                    object\n",
      "suicides_no             int64\n",
      "population              int64\n",
      "suicides/100k pop     float64\n",
      "country-year           object\n",
      "HDI for year          float64\n",
      " gdp_for_year ($)       int64\n",
      "gdp_per_capita ($)      int64\n",
      "generation             object\n",
      "dtype: object\n",
      "Count of duplicates: 27820\n",
      "country               False\n",
      "year                  False\n",
      "sex                   False\n",
      "age                   False\n",
      "suicides_no           False\n",
      "population            False\n",
      "suicides/100k pop     False\n",
      "country-year          False\n",
      "HDI for year           True\n",
      " gdp_for_year ($)     False\n",
      "gdp_per_capita ($)    False\n",
      "generation            False\n",
      "dtype: bool\n",
      "\"HDI for year\" is the only column with NaN.  Let's compare how many NaN 27820 vs 27820 non-NaN of a total of 27820 samples\n",
      "count    8364.000000\n",
      "mean        0.776601\n",
      "std         0.093367\n",
      "min         0.483000\n",
      "25%         0.713000\n",
      "50%         0.779000\n",
      "75%         0.855000\n",
      "max         0.944000\n",
      "Name: HDI for year, dtype: float64\n",
      "This is reporting specious results.  DataFrame.describe() is showing 8364 non-NaN values.  Let's fill NaN with the means and see what that changes.\n",
      "count    27820.000000\n",
      "mean         0.776601\n",
      "std          0.051192\n",
      "min          0.483000\n",
      "25%          0.776601\n",
      "50%          0.776601\n",
      "75%          0.776601\n",
      "max          0.944000\n",
      "Name: HDI for year, dtype: float64\n",
      "country ['Albania' 'Antigua and Barbuda' 'Argentina' 'Armenia' 'Aruba' 'Australia'\n",
      " 'Austria' 'Azerbaijan' 'Bahamas' 'Bahrain' 'Barbados' 'Belarus' 'Belgium'\n",
      " 'Belize' 'Bosnia and Herzegovina' 'Brazil' 'Bulgaria' 'Cabo Verde'\n",
      " 'Canada' 'Chile' 'Colombia' 'Costa Rica' 'Croatia' 'Cuba' 'Cyprus'\n",
      " 'Czech Republic' 'Denmark' 'Dominica' 'Ecuador' 'El Salvador' 'Estonia'\n",
      " 'Fiji' 'Finland' 'France' 'Georgia' 'Germany' 'Greece' 'Grenada'\n",
      " 'Guatemala' 'Guyana' 'Hungary' 'Iceland' 'Ireland' 'Israel' 'Italy'\n",
      " 'Jamaica' 'Japan' 'Kazakhstan' 'Kiribati' 'Kuwait' 'Kyrgyzstan' 'Latvia'\n",
      " 'Lithuania' 'Luxembourg' 'Macau' 'Maldives' 'Malta' 'Mauritius' 'Mexico'\n",
      " 'Mongolia' 'Montenegro' 'Netherlands' 'New Zealand' 'Nicaragua' 'Norway'\n",
      " 'Oman' 'Panama' 'Paraguay' 'Philippines' 'Poland' 'Portugal'\n",
      " 'Puerto Rico' 'Qatar' 'Republic of Korea' 'Romania' 'Russian Federation'\n",
      " 'Saint Kitts and Nevis' 'Saint Lucia' 'Saint Vincent and Grenadines'\n",
      " 'San Marino' 'Serbia' 'Seychelles' 'Singapore' 'Slovakia' 'Slovenia'\n",
      " 'South Africa' 'Spain' 'Sri Lanka' 'Suriname' 'Sweden' 'Switzerland'\n",
      " 'Thailand' 'Trinidad and Tobago' 'Turkey' 'Turkmenistan' 'Ukraine'\n",
      " 'United Arab Emirates' 'United Kingdom' 'United States' 'Uruguay'\n",
      " 'Uzbekistan']\n",
      "sex ['male' 'female']\n",
      "age ['15-24 years' '35-54 years' '75+ years' '25-34 years' '55-74 years'\n",
      " '5-14 years']\n",
      "country-year ['Albania1987' 'Albania1988' 'Albania1989' ... 'Uzbekistan2012'\n",
      " 'Uzbekistan2013' 'Uzbekistan2014']\n",
      "generation ['Generation X' 'Silent' 'G.I. Generation' 'Boomers' 'Millenials'\n",
      " 'Generation Z']\n",
      "['country', 'year', 'sex', 'age', 'suicides_no', 'population', 'suicides/100k pop', 'HDI for year', ' gdp_for_year ($) ', 'gdp_per_capita ($)', 'generation'] \n",
      " ['country', 'year', 'sex', 'age', 'suicides_no', 'population', 'HDI for year', ' gdp_for_year ($) ', 'gdp_per_capita ($)', 'generation'] \n",
      " suicides/100k pop \n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Pandas DataFrame.corrwith():\n",
      "--------------------------------------------------\n",
      "country               0.055224\n",
      "year                 -0.039037\n",
      "sex                   0.391496\n",
      "age                   0.187215\n",
      "suicides_no           0.306604\n",
      "population            0.008285\n",
      "suicides/100k pop     1.000000\n",
      "HDI for year          0.037290\n",
      " gdp_for_year ($)     0.025240\n",
      "gdp_per_capita ($)    0.001785\n",
      "generation           -0.049820\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "df = pd.read_csv('./datasets/master.csv', thousands=',')\n",
    "#############################################\n",
    "####  Cleanup the data\n",
    "# Checkin\n",
    "## what are the columns that are strings\n",
    "## how many unique values in these columns?\n",
    "# Test 1\n",
    "## drop CountryYear, \n",
    "## one hot encode country\n",
    "# Test 2\n",
    "## drop county, year\n",
    "## one-hot encode CountryYear\n",
    "# One-hot encode generation\n",
    "#############################################\n",
    "print(df.dtypes)\n",
    "\n",
    "\n",
    "# Check for duplicates, this adds a new column to the dataset\n",
    "print(f'Count of duplicates: {len(df.duplicated())}')\n",
    "## none, good\n",
    "\n",
    "\n",
    "print(f'{df.isna().any()}')\n",
    "## \n",
    "print(f'\"HDI for year\" is the only column with NaN.  Let\\'s compare how many NaN {df[\"HDI for year\"].isna().count()} vs {df[\"HDI for year\"].notna().count()} non-NaN of a total of {len(df[\"HDI for year\"])} samples')\n",
    "print(df[\"HDI for year\"].describe())\n",
    "print(f'This is reporting specious results.  DataFrame.describe() is showing 8364 non-NaN values.  Let\\'s fill NaN with the means and see what that changes.')\n",
    "# df.loc[:,df[\"HDI for year\"].isna()] = df[\"HDI for year\"].mean()\n",
    "# df.fillna(df[\"HDI for year\"].mean())\n",
    "mean_value = df['HDI for year'].mean()\n",
    "df['HDI for year'] = np.where(df['HDI for year'].isna(), mean_value, df['HDI for year'])\n",
    "print(df['HDI for year'].describe())\n",
    "\n",
    "## Using the method described in the module notebook, check unique values by column\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == object:\n",
    "        print(col, df[col].unique())\n",
    "\n",
    "## We will remove country-year since it is described by two other columns, one of which is numeric\n",
    "df = df.drop(columns=['country-year'])\n",
    "\n",
    "\n",
    "## LabelEncoder\n",
    "# Encode object types. They are all strings.  Save the labelencoders paired with the column names so we can reverse the values later\n",
    "columns_to_encode = df.select_dtypes(include='object')\n",
    "encoders = dict.fromkeys(columns_to_encode)\n",
    "for column in columns_to_encode:\n",
    "    le = LabelEncoder()\n",
    "    df[column] = le.fit_transform(df[column].astype(str))\n",
    "    encoders[column] = le\n",
    "\n",
    "#############################################\n",
    "### Read the data\n",
    "#############################################\n",
    "# df = pd.read_csv('./datasets/master.csv', thousands=',')\n",
    "labels = list(df.columns)\n",
    "feature_labels = list(df.columns)\n",
    "target_label = 'suicides/100k pop'\n",
    "feature_labels.remove(target_label)\n",
    "X = df.drop(target_label, axis=1).values\n",
    "y = df[target_label].values\n",
    "print(labels, '\\n',feature_labels, '\\n', target_label, '\\n', )\n",
    "print(f'\\n\\n{\"-\"*50}\\nPandas DataFrame.corrwith():\\n{\"-\"*50}\\n{df.corrwith(df[target_label])}')\n",
    "print('\\n\\n\\n')\n",
    "\n",
    "\n",
    "\n",
    "#######################################################################\n",
    "##          From the book\n",
    "#######################################################################\n",
    "\n",
    "# ### sc = StandardScaler()\n",
    "# X_train_std = sc.fit_transform(X_train)\n",
    "\n",
    "# df = pd.read_csv('./datasets/master.csv', thousands=',')\n",
    "# feat_labels = df.columns[1:]\n",
    "\n",
    "# forest = RandomForestClassifier(n_estimators=500,\n",
    "#                                 random_state=1)\n",
    "\n",
    "# forest.fit(X_train, y_train)\n",
    "# importances = forest.feature_importances_\n",
    "\n",
    "# indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# for f in range(X_train.shape[1]):\n",
    "#     print(\"%2d) %-*s %f\" % (f + 1, 30, \n",
    "#                             feat_labels[indices[f]], \n",
    "#                             importances[indices[f]]))\n",
    "\n",
    "# plt.title('Feature importance')\n",
    "# plt.bar(range(X_train.shape[1]), \n",
    "#         importances[indices],\n",
    "#         align='center')\n",
    "\n",
    "# plt.xticks(range(X_train.shape[1]), \n",
    "#            feat_labels[indices], rotation=90)\n",
    "# plt.xlim([-1, X_train.shape[1]])\n",
    "# plt.tight_layout()\n",
    "# # plt.savefig('figures/04_10.png', dpi=300)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f42691-5d0f-472d-b839-727c43ba69c4",
   "metadata": {},
   "source": [
    "#### 4. Answer\n",
    "\n",
    "TODO: describe the steps I outline in my comments, and what I actually did."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7987d691-2268-4e51-b85f-8a71c19362dc",
   "metadata": {},
   "source": [
    "### 5. [20 pts] Pre-process the dataset and list the major features you want to use. Note that not all features are crucial. For example, country-year variable is a derived feature and for a classifier it would not be necessary to include the year, the country and the country -year together. In fact, one must avoid adding a derived feature and the original at the same time.\n",
    "List the independent features you want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cf4b16-c88b-4390-a645-7e803f3a6625",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75406b89-4755-423e-a31c-cf92bbb7b3e5",
   "metadata": {},
   "source": [
    "### 6. [20 pts] Devise a classification problem and present a working prototype model. (It does not have to perform great, but it has to be functional.) Note that we will continue with this problem in the following modules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9771cb1b-6b4a-40d1-87af-82740e585329",
   "metadata": {},
   "source": [
    "# References\n",
    "1. Raschka, Sebastian, et al. Machine Learning with PyTorch and Scikit-Learn: Develop machine learning and deep learning models with Python. Packt Publishing Ltd, 2022.\n",
    "2. Guven, Erhan. Applied Machine Learning: Module 3 Notebook.  Last accesses 6 February, 2025."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
