{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8487b4db-5dd3-4aa4-ad1b-ba5d5317ef58",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf0e72b7-a80a-4da4-8cf5-4eb3950fd956",
   "metadata": {},
   "source": [
    "# 1. [20 pts] At a high level (i.e., without entering into mathematical details), please describe, compare, and contrast the following classifiers:\n",
    " - Perceptron (textbook's version)\n",
    " - SVM\n",
    " - Decision Tree\n",
    " - Random Forest (you have to research a bit about this classifier)\n",
    "\n",
    "\n",
    "Some comparison criterion can be:\n",
    " - Speed?\n",
    " - Strength?\n",
    " - Robustness?\n",
    " - The feature type that the classifier naturally uses (e.g. relying on distance means that\n",
    "numerical features are naturally used)\n",
    " - Is it statistical?\n",
    " - Does the method solve an optimization problem? If yes, what is the cost function?\n",
    "\n",
    "\n",
    "Which one will be the first that you would try on your dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85e634e-774b-4315-b112-3c98e5fcd5f9",
   "metadata": {},
   "source": [
    "### Answer 1\n",
    "- speed:  _Find a definition for this and include it here._ compare time to build model of each on one of the datasets we \"cleaned\"\n",
    "- strength:  _Find a definition for this and include it here._ compare the score of each for the prior dataset. \n",
    "- robustness:  _Find a definition for this and include it here._ test on data never seen\n",
    "- Decision tree: doesn't require feature scaling.  Not as robust as Random Forest-- more susceptible to overfitting and doesn't generalize as well. [1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b41d64-e8c9-4d79-aaa9-6c81c1e52a50",
   "metadata": {},
   "source": [
    "# 2. [20 pts] Define the following feature types and give example values from a dataset. You can pull examples from an existing dataset (like the Iris dataset) or you could write out a dataset yourself. (Hint: In order to give examples for each feature type, you will probably have to use more than one dataset.)\n",
    " - Numerical\n",
    " - Nominal\n",
    " - Date\n",
    " - Text\n",
    " - Image\n",
    " - Dependent variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85166b7b-5d1b-4339-8a7e-e5c4139624e4",
   "metadata": {},
   "source": [
    "### Answer 2\n",
    " - Numerical: characteristics of features represented by numerical values.  In the Iris dataset `petal length`, `petal width`, `sepal length`, `sepal width` are all numeric features.\n",
    " - Nominal: are descriptive features, without numerica characteristics.  On Kaggle there is a dataset named [Vehicle Dataset](https://www.kaggle.com/datasets/nehalbirla/vehicle-dataset-from-cardekho).  The `Name` feature contains information on the make, model and trim level of the car, which are each features in themselves.\n",
    " - Date: These features indicate a time related to the sample.  They can be values such as `year`, `month`, `day`, `hour`, `minute`, `second`, `millisecond`.  The [Vehicle Dataset](https://www.kaggle.com/datasets/nehalbirla/vehicle-dataset-from-cardekho) contains `year`. Another dataset with more date features is [Room Occupancy Estimation](https://archive.ics.uci.edu/dataset/864/room+occupancy+estimation) which contains `date` and `time` features.  `date` is formatted as YYYY/MM/DD, `time` is formatted as HH:MM:SS.\n",
    " - Text: these are sentences, or words.  They are used in tasks like sentiment analysis, or perhaps something like classifying a support ticket as \"hardware issue\" or \"finance issue.\"  An example of a sentiment analysis dataset is the [Customer Feedback Dataset](https://www.kaggle.com/datasets/vishweshsalodkar/customer-feedback-dataset) on Kaggle.  The dataset shows only one feature, `Text, Sentiment, Source, Date/Time, User ID, Location, Confidence Score`, but on inspection we can see that the first field in this single feature is itself a `text` feature.  Another dataset rich with text is the [Support-tickets-classification](https://www.kaggle.com/datasets/aniketg11/supportticketsclassification) dataset on Kaggle.  It contains text features `title` and `body` which can be used to determine what team is responsible for the ticket.\n",
    " - Image: image features are just that--images.  From what I've read it appears that you will always need to transform the images into RGB with values (0,255).  An example dataset is the [AI vs. Human-Generated Images](https://www.kaggle.com/datasets/alessandrasala79/ai-vs-human-generated-dataset).  This dataset contains a CSV with relative paths to image files, the feature is called `file_name`.  Another example of images in a dataset is [Olivetti Faces](https://scikit-learn.org/stable/datasets/real_world.html#olivetti-faces-dataset) which I reviewed on Scikit-Learn's website.  The dataset has an `images` feature which has 400 samples, each of which is 64x64 matrix of grayscale image values.\n",
    " - Dependent variable: this is a variable which is determined by features (or independent variables).  In the Iris dataset these are the species Iris-Setosa, Iris-Versicolour, Iris-Virginica.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b756049c-0143-475d-9fb3-3358343e6181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading Olivetti faces from https://ndownloader.figshare.com/files/5976027 to /Users/ace/scikit_learn_data\n"
     ]
    }
   ],
   "source": [
    "### Code 2\n",
    "\n",
    "# Directly from https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_olivetti_faces.html#sklearn.datasets.fetch_olivetti_faces\n",
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "olivetti_faces = fetch_olivetti_faces()\n",
    "print(f'Shape of Olivetti faces dataset: {olivetti_faces.data.shape}')\n",
    "print(f'Shape of Olivetti faces dataset: {olivetti_faces.data.columns}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3b4209-5f9b-416d-97e2-7ba92fda9042",
   "metadata": {},
   "source": [
    "# 3. [20 pts] Using online resources, research and find other classifier performance metrics which are also as common as the accuracy metric. Provide the mathematical equations for them and explain in your own words the meaning of the different metrics you found. Note that providing mathematical equations might involve defining some more fundamental terms, e.g. you should define “False Positive,” if you answer with a metric that builds on that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80605753-102e-4b9f-b187-cbaea653e749",
   "metadata": {},
   "source": [
    "# 4. [40 pts] Implement a correlation program from scratch to look at the correlations between the features of Admission_Predict.csv dataset file. (This Graduate Admission dataset, with 9 features and 500 data points, is not provided on Canvas; you have to download it from Kaggle by following the instructions in the module Jupyter notebook.) Remember, you are not allowed to used numpy functions such as mean(), stdev(), cov(), etc. You may use DataFrame.corr() only to verify the correctness of your from-scratch matrix.\n",
    "## Display the correlation matrix where each row and column are the features. (Hint: this\n",
    "should be an 8 by 8 matrix.)\n",
    " - Should we use 'Serial no'? Why or why not?\n",
    " - Observe that the diagonal of this matrix should have all 1's; why is this?\n",
    " - Since the last column can be used as the target (dependent) variable, what do you\n",
    "think about the correlations between all the variables?\n",
    " - Which variable should be the most important to try to predict 'Chance of Admit'?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe28c2c7-a6a1-41b6-bf27-1f0a6c18482a",
   "metadata": {},
   "source": [
    "# References\n",
    "1. Raschka, Sebastian, et al. Machine Learning with PyTorch and Scikit-Learn: Develop machine learning and deep learning models with Python. Packt Publishing Ltd, 2022.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
