{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c82495d4-a94b-4783-aabf-6dfcab2a412a",
   "metadata": {},
   "source": [
    "# Assignment 5\n",
    "\n",
    "We will develop a classification pipeline to predict if a passenger from the Titanic survived or not. Go to Kaggle page for Titanic data and download the training and testing data sets. (Verification: 891 data points for training and 418 data points for testing dataset files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e062b27-8a71-4874-90ea-923eac32845c",
   "metadata": {},
   "source": [
    "# 1. [70 pts] \n",
    "Preprocess the data, impute missing values as you see fit, and remove features that seem useless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1db2a214-0f04-4ca9-a765-552b312beaec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "\n",
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n",
      "PassengerId      int64\n",
      "Survived         int64\n",
      "Pclass           int64\n",
      "Name            object\n",
      "Sex             object\n",
      "Age            float64\n",
      "SibSp            int64\n",
      "Parch            int64\n",
      "Ticket          object\n",
      "Fare           float64\n",
      "Cabin           object\n",
      "Embarked        object\n",
      "dtype: object\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "\n",
      "\n",
      "\n",
      "Testing\n",
      "\n",
      "       PassengerId      Pclass         Age       SibSp       Parch        Fare\n",
      "count   418.000000  418.000000  332.000000  418.000000  418.000000  417.000000\n",
      "mean   1100.500000    2.265550   30.272590    0.447368    0.392344   35.627188\n",
      "std     120.810458    0.841838   14.181209    0.896760    0.981429   55.907576\n",
      "min     892.000000    1.000000    0.170000    0.000000    0.000000    0.000000\n",
      "25%     996.250000    1.000000   21.000000    0.000000    0.000000    7.895800\n",
      "50%    1100.500000    3.000000   27.000000    0.000000    0.000000   14.454200\n",
      "75%    1204.750000    3.000000   39.000000    1.000000    0.000000   31.500000\n",
      "max    1309.000000    3.000000   76.000000    8.000000    9.000000  512.329200\n",
      "PassengerId      int64\n",
      "Pclass           int64\n",
      "Name            object\n",
      "Sex             object\n",
      "Age            float64\n",
      "SibSp            int64\n",
      "Parch            int64\n",
      "Ticket          object\n",
      "Fare           float64\n",
      "Cabin           object\n",
      "Embarked        object\n",
      "dtype: object\n",
      "   PassengerId  Pclass                                          Name     Sex  \\\n",
      "0          892       3                              Kelly, Mr. James    male   \n",
      "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
      "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
      "3          895       3                              Wirz, Mr. Albert    male   \n",
      "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
      "\n",
      "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
      "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
      "1  47.0      1      0   363272   7.0000   NaN        S  \n",
      "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
      "3  27.0      0      0   315154   8.6625   NaN        S  \n",
      "4  22.0      1      1  3101298  12.2875   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "X_train = pd.read_csv('datasets/train.csv')\n",
    "y = pd.read_csv('datasets/test.csv')\n",
    "\n",
    "\n",
    "print('Training\\n')\n",
    "print(X_train.describe())\n",
    "print(X_train.dtypes)\n",
    "print(X_train.head())\n",
    "\n",
    "print();print();print()\n",
    "\n",
    "print('Testing\\n')\n",
    "print(y.describe())\n",
    "print(y.dtypes)\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "813bc305-89ef-4da7-a72a-505bb176a9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_columns_uniques(df_name, df):\n",
    "    for c in df.columns:\n",
    "        print(f'[{df_name}]\\tcolumn: \"{c}\" \\t total cells: { len(df[c]) } \\t Non-Null count: { df[c].count() } \\t Null%: { (1 - (df[c].count()/len(df[c])))*100 }\\n')\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0819dcd3-d96e-411b-a77d-23e1397e2ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[y]\tcolumn: \"PassengerId\" \t total cells: 418 \t Non-Null count: 418 \t Null%: 0.0\n",
      "\n",
      "[y]\tcolumn: \"Pclass\" \t total cells: 418 \t Non-Null count: 418 \t Null%: 0.0\n",
      "\n",
      "[y]\tcolumn: \"Name\" \t total cells: 418 \t Non-Null count: 418 \t Null%: 0.0\n",
      "\n",
      "[y]\tcolumn: \"Sex\" \t total cells: 418 \t Non-Null count: 418 \t Null%: 0.0\n",
      "\n",
      "[y]\tcolumn: \"Age\" \t total cells: 418 \t Non-Null count: 332 \t Null%: 20.574162679425832\n",
      "\n",
      "[y]\tcolumn: \"SibSp\" \t total cells: 418 \t Non-Null count: 418 \t Null%: 0.0\n",
      "\n",
      "[y]\tcolumn: \"Parch\" \t total cells: 418 \t Non-Null count: 418 \t Null%: 0.0\n",
      "\n",
      "[y]\tcolumn: \"Ticket\" \t total cells: 418 \t Non-Null count: 418 \t Null%: 0.0\n",
      "\n",
      "[y]\tcolumn: \"Fare\" \t total cells: 418 \t Non-Null count: 417 \t Null%: 0.23923444976076125\n",
      "\n",
      "[y]\tcolumn: \"Cabin\" \t total cells: 418 \t Non-Null count: 91 \t Null%: 78.22966507177034\n",
      "\n",
      "[y]\tcolumn: \"Embarked\" \t total cells: 418 \t Non-Null count: 418 \t Null%: 0.0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[X_train]\tcolumn: \"PassengerId\" \t total cells: 891 \t Non-Null count: 891 \t Null%: 0.0\n",
      "\n",
      "[X_train]\tcolumn: \"Survived\" \t total cells: 891 \t Non-Null count: 891 \t Null%: 0.0\n",
      "\n",
      "[X_train]\tcolumn: \"Pclass\" \t total cells: 891 \t Non-Null count: 891 \t Null%: 0.0\n",
      "\n",
      "[X_train]\tcolumn: \"Name\" \t total cells: 891 \t Non-Null count: 891 \t Null%: 0.0\n",
      "\n",
      "[X_train]\tcolumn: \"Sex\" \t total cells: 891 \t Non-Null count: 891 \t Null%: 0.0\n",
      "\n",
      "[X_train]\tcolumn: \"Age\" \t total cells: 891 \t Non-Null count: 714 \t Null%: 19.865319865319865\n",
      "\n",
      "[X_train]\tcolumn: \"SibSp\" \t total cells: 891 \t Non-Null count: 891 \t Null%: 0.0\n",
      "\n",
      "[X_train]\tcolumn: \"Parch\" \t total cells: 891 \t Non-Null count: 891 \t Null%: 0.0\n",
      "\n",
      "[X_train]\tcolumn: \"Ticket\" \t total cells: 891 \t Non-Null count: 891 \t Null%: 0.0\n",
      "\n",
      "[X_train]\tcolumn: \"Fare\" \t total cells: 891 \t Non-Null count: 891 \t Null%: 0.0\n",
      "\n",
      "[X_train]\tcolumn: \"Cabin\" \t total cells: 891 \t Non-Null count: 204 \t Null%: 77.1043771043771\n",
      "\n",
      "[X_train]\tcolumn: \"Embarked\" \t total cells: 891 \t Non-Null count: 889 \t Null%: 0.22446689113355678\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_columns_uniques('y', y)\n",
    "\n",
    "print_columns_uniques('X_train', X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79391ae2-6d64-49d7-8f09-bd09fbf5949a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "\n",
    "def get_last_name(name):\n",
    "    '''\n",
    "        Assumes name is in the format\n",
    "        <Last Name>, <rest of name>\n",
    "    '''\n",
    "    return name.lower().strip().split(',')[0]\n",
    "\n",
    "def drop_cols(df, cols):\n",
    "    return\n",
    "\n",
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('last_name', get_last_name, ['a', 'b']) \n",
    "    ],\n",
    "    remainder='passthrough'  # Keep other columns unchanged\n",
    ")\n",
    "\n",
    "\n",
    "# Custom transformer for specific column imputation\n",
    "class SpecificColumnImputer(BaseEstimator, TransformerMixin):\n",
    "    '''\n",
    "        Transformer to be applied to the Cabin column, to fill in missing values\n",
    "    '''\n",
    "    def __init__(self, column, strategy='constant', fill_value=None):\n",
    "        self.column = column\n",
    "        self.strategy = strategy\n",
    "        self.fill_value = fill_value\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        imputer = SimpleImputer(strategy=self.strategy, fill_value=self.fill_value)\n",
    "        X[[self.column]] = imputer.fit_transform(X[[self.column]])\n",
    "        return X\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X)\n",
    "\n",
    "# Create a pipeline with the custom transformer\n",
    "columns_to_drop=['PassengerId', 'Ticket']\n",
    "numeric_columns = [c for c in X_train.columns if X_train[c].dtypes != 'object' and c not in columns_to_drop]\n",
    "pipeline = Pipeline([\n",
    "    ('drop_cols', FunctionTransformer(lambda df: df.drop(columns_to_drop, axis=1) )),\n",
    "    # (ColumnTransformer(get_last_name) ), \n",
    "    ('specific_imputer', SpecificColumnImputer(column='Cabin', strategy='constant', fill_value='probably_rough')),\n",
    "    # ('other_imputer', SimpleImputer(strategy='mean'))  \n",
    "])\n",
    "\n",
    "# Fit and transform the DataFrame using the pipeline\n",
    "X_imputed = pipeline.fit_transform(X_train)\n",
    "\n",
    "print(numeric_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e96356-0494-483b-82c5-5107f5f88bb3",
   "metadata": {},
   "source": [
    "### 1 Answer\n",
    "I will be using a RandomForestClassifier.  By investigating nulls in each column of each dataset we can an idea of where imputation is needed.  Steps I took to process are:\n",
    "\n",
    "- Split `X_train` into `X_train` and `y_train`\n",
    "- `Ticket` is a ticket number and seems useless.  Maybe there is something to be extracted, but it's not obvious. Drop the column.\n",
    "- `PassengerId` is an ID column.  Perhaps lower numbers meant higher class fares, however we don't have that detail. Drop the column.\n",
    "- Perhaps \"LastName\" has something to do with survival.  Since this can be extracted by getting the column value to the left of the first \",\". This is easy to do so we will\n",
    "- `Cabin` is mostly null. To me this indicates that the column is important, and that most people are in an unamed cabin.  For that I will define a custom imputer.\n",
    "\n",
    "# TODO:\n",
    "- Fill unknown numeric features with `mean`\n",
    "- Fill unknown object features with `most_frequent`\n",
    "- Apply feature scaling to `Age`, `Fare`\n",
    "- Apply Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b21e284-981a-4318-8f2a-fb564fd5c12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived int64\n",
      "Pclass int64\n",
      "Name object\n",
      "Sex object\n",
      "Age float64\n",
      "SibSp int64\n",
      "Parch int64\n",
      "Fare float64\n",
      "Cabin object\n",
      "Embarked object\n"
     ]
    }
   ],
   "source": [
    "for c in X_imputed.columns:\n",
    "    print(c, X_imputed[c].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf0f9d3-b763-42b4-95bd-ae2de5542447",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
